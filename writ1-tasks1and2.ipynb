{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb5b703",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee66811",
   "metadata": {},
   "source": [
    "It is 2022, and companies all over the world are still reeling from the impact that COVID-19 has had on them. AirBnb is one of these businesses, and the hosts that list their spare rooms or extra homes are trying their hardest to make their places look as appealing as possible to tempt travellers to spend their hard earned money.\n",
    "\n",
    "In this project I will aim to answer the following question:\n",
    "\n",
    "### \"What can hosts do to maximise their chances of rental to increase income? How does this differ across Europe, if at all?\"\n",
    "\n",
    "This can be broken down into several sub-questions:\n",
    "\n",
    "1. What hosts' behaviors or profiles would influence AirBNB tenants reviews across Europe?\n",
    " \n",
    "2. What words should hosts include in listings?\n",
    " \n",
    "3. What features should hosts focus on to maximise booking potential?\n",
    " \n",
    "\n",
    "## The dataset\n",
    "\n",
    "The dataset used for this project comes from [insideairbnb.com](http://insideairbnb.com/), an investigatory/watchdog website launched by Murray Cox in 2016. It reports and visualizes scraped data on the property rental marketplace company Airbnb,focusing on highlighting illegal renting on the site and gentrification caused by landlords buying properties to rent on Airbnb.\n",
    "\n",
    "\n",
    "The data is quite messy, and has some limitations. The major one is that it only includes the advertised price (sometimes called the 'sticker' price). The sticker price is the overall nightly price that is advertised to potential guests, rather than the actual average amount paid per night by previous guests. The advertised prices can be set to any arbitrary amount by the host, and hosts that are less experienced with Airbnb will often set these to very low (e.g. £0) or very high (e.g. £10,000) amounts.\n",
    "\n",
    "Nevertheless, this dataset can be used as a proof of concept. A more accurate version could be built using data on the actual average nightly rates paid, e.g. from sites like [AirDNA](https://www.airdna.co/) that sell higher quality Airbnb data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa5dae0-b9cf-49c1-94ac-d9c0d4f78bcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be1127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from pylab import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import  r2_score, mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "import folium\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import collections\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eafe60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting seaborn size parameters\n",
    "sns.set(rc={'figure.figsize':(15,8)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f4ced9",
   "metadata": {},
   "source": [
    "First, I will undertake some basic preprocessing of the data and carry out some exploratory data analysis for both cities. This will allow us to get some insight into the data before attempting to answer the question set in Task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6a156f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exploratory Data Analysis (Amsterdam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84c493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in Amsterdam data\n",
    "ams = pd.read_csv('airbnb_amsterdam/listings.csv')\n",
    "ams.set_index('id',inplace=True)\n",
    "ams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ffcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dbc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_listings = len(ams)\n",
    "num_hosts = len(ams['host_id'].unique())\n",
    "\n",
    "print(f'The Amsterdam data contains information about {num_listings} AirBnB listings from {num_hosts} hosts.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829b5756",
   "metadata": {},
   "outputs": [],
   "source": [
    "ams.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f21e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ams.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5002f0",
   "metadata": {},
   "source": [
    "Most of the features are numeric, with some continuous floats such as `latitude` and `longitude`, and some integer variables such as `price`, `minimum_nights` and `availability_365`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc66315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnecessary columns\n",
    "ams.drop(['host_name','last_review', 'neighbourhood_group'], axis=1, inplace=True)\n",
    "# Visualize the first 5 rows\n",
    "ams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4413d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null values\n",
    "ams.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f712a09f",
   "metadata": {},
   "source": [
    "The missing values in the `reviews_per_month` column correspond to rows where there are no reviews. As there have been no reviews left for this listing, the number of reviews per month cannot be calculated. This means that we can fill the null values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33744c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing null values in reviews_per_month column with 0\n",
    "ams.fillna({'reviews_per_month':0}, inplace=True)\n",
    "#replacing null values in name column with an empty string\n",
    "ams['name'] = ams[['name']].fillna((''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6087d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#examining the dataset\n",
    "(ams[['price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month',\n",
    "       'calculated_host_listings_count', 'availability_365']]\n",
    " .describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6589fceb",
   "metadata": {},
   "source": [
    "From the table above, we can see that the minimum price for a room is 0. This is obviously an error, so the Amsterdam data will be changed to just show listings with prices over £0 per night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d17b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only include listings where price >0 \n",
    "ams = ams.loc[ams['price'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca6897d",
   "metadata": {},
   "source": [
    "Similarly, the maximum value for `minimum_nights` is 1001, which equates to nearly three years as a minimum stay! For the purpose of this project, we will remove all values of `minimum_nights` that are over 31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a59bd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ams = ams.loc[ams['minimum_nights'] < 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf975a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataset for the correlation matrix, removing unnecessary variables\n",
    "corr_ams = ams[['price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month',\n",
    "       'calculated_host_listings_count', 'availability_365']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74e3abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = corr_ams.quantile(q=.25)\n",
    "Q3 = corr_ams.quantile(q=.75)\n",
    "IQR = corr_ams.apply(stats.iqr)\n",
    "\n",
    "ams_no_outliers = corr_ams[~((corr_ams < (Q1-1.5*IQR)) | (corr_ams > (Q3+1.5*IQR))).any(axis=1)]\n",
    "ams_no_outliers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacfc74d",
   "metadata": {},
   "source": [
    "We can now use some basic Natural Language Processing (NLP) to create a word cloud of the most common words and phrases used in listings names for places in Amsterdam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e52623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a series of Amsterdam listing names\n",
    "ams_name = ams['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6b7d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(str(each) for each in ams_name)\n",
    "# Create and generate a word cloud image:\n",
    "wordcloud = WordCloud(max_words=200, background_color=\"white\").generate(text)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.figure(figsize=(15,10))\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='Bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbf37a4",
   "metadata": {},
   "source": [
    "Unsuprisingly, \"Amsterdam\" is one of the most commonly mentioned words in the dataset. Other words include city center/centre, spacious, beautiful, and apartment. Later on we can see if the common use of the word 'apartment' corresponds to the number of apartment listings in the Amsterdam data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580ba0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing puncuation\n",
    "text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "#removing numbers\n",
    "text = ''.join([i for i in text if not i.isdigit()])\n",
    "#making all text lower case\n",
    "text = text.lower()\n",
    "#removing stop words from text to include only words that are relevant\n",
    "text = remove_stopwords(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b39a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the Counter instance 'most_common' call to a variable\n",
    "word_frequency = Counter(\"\".join(text).split()).most_common(10)\n",
    "\n",
    "#'most_common' returns a list of (word, count) tuples\n",
    "words = [word for word, _ in word_frequency]\n",
    "counts = [counts for _, counts in word_frequency]\n",
    "\n",
    "#creating plot\n",
    "\n",
    "plt.bar(words, counts, color = '#ff8882')\n",
    "plt.title(\"10 most frequent tokens in description\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Words\")\n",
    "xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc9425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "#creating distplots for each variable\n",
    "subplot(2,3,1)\n",
    "sns.distplot(ams['price'])\n",
    "\n",
    "subplot(2,3,2)\n",
    "sns.distplot(ams['minimum_nights'])\n",
    "\n",
    "subplot(2,3,3)\n",
    "sns.distplot(ams['number_of_reviews'])\n",
    "\n",
    "subplot(2,3,4)\n",
    "sns.distplot(ams['reviews_per_month'])\n",
    "\n",
    "subplot(2,3,4)\n",
    "sns.distplot(ams['availability_365'])\n",
    "\n",
    "plt.tight_layout() # avoid overlap of plots\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee76ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "#creating boxplots for each variable\n",
    "subplot(2,3,1)\n",
    "sns.boxplot(y = ams['price']) \n",
    "\n",
    "subplot(2,3,2)\n",
    "sns.boxplot(y = ams['minimum_nights'])\n",
    "\n",
    "subplot(2,3,3)\n",
    "sns.boxplot(y = ams['number_of_reviews'])\n",
    "\n",
    "subplot(2,3,4)\n",
    "sns.boxplot(y = ams['reviews_per_month'])\n",
    "\n",
    "subplot(2,3,6)\n",
    "sns.boxplot(y = ams['availability_365'])\n",
    "\n",
    "plt.tight_layout() # avoid overlap of plots\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d27f533",
   "metadata": {},
   "source": [
    "What's immediately evident from these boxplots is the number of outliers for each variable. This matches with how right skewed each of the distribution plots above are, as they show the data to be very positively skewed with a mean to the right of the median.  \n",
    "\n",
    "Another thing that is noticeable is how positively skewed the boxplot for `availability_365` is. The outliers take up nearly 85% of the whole chart.\n",
    "\n",
    "We can also create a bar chart to see the counts of values for `room_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503e4358",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Properties per Room Type'\n",
    "sns.countplot(ams['room_type'])\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0121e520",
   "metadata": {},
   "source": [
    "The bar chart clearly shows that entire homes and apartments are by far the most popular room type in Amsterdam, with almost 16,000 listings. Shared rooms are few and far between, with the bar not visible.\n",
    "\n",
    "We can also look at the count of listings for each neighbourhood in Amsterdam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99cb5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a countplot\n",
    "title = 'Properties per Neighbourhood'\n",
    "ax = sns.countplot(ams['neighbourhood'])\n",
    "\n",
    "#setting font size and rotation\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c23419",
   "metadata": {},
   "source": [
    "We can see that neighbourhoods such as De Baarsjes - Oud West, De Pijp - Rivierenbuurt and Centrum West are three of the most popular in Amsterdam, whereas the Bijlmer-Oost, Bijlmer-Centrum and Gaasperdam-Driemond neighbourhoods are much less popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f19a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataset for the correlation matrix, removing unnecessary variables\n",
    "corr_ams = ams[['price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month',\n",
    "       'calculated_host_listings_count', 'availability_365']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0812baad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "title = 'Correlation matrix of numerical variables'\n",
    "sns.heatmap(corr_ams.corr(), annot=True, square=True, cmap='Reds')\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030345bb",
   "metadata": {},
   "source": [
    "The above correlation matrix shows the correlation between the numerical values in the dataset. The following conclusions can be reached from this:\n",
    "\n",
    "* None of the variables are particularly negatively correlated (all correlations are above -0.1)\n",
    "\n",
    "* The strongest positive correlation is between `reviews_per_month` and `number_of_reviews` (0.66), which makes sense as the more reviews a listing has, the more reviews it will have in a month.\n",
    "\n",
    "* The `availability_365` variable seems to positively affect several other variables. For example, the higher the availability of a room, the more reviews the listing will have (again, this makes sense as the room is available for more days so more people have the opportunity to review it). Additionally, the higher the availability of a room, the higher the price of the room."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d210ff3f",
   "metadata": {},
   "source": [
    "Next, we can see where listings are in relation to their latitude and longitude. Using a scatterplot will create a map-like image for us to see where neighbourhoods are positioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19844244",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Neighbourhood Location'\n",
    "plt.figure(figsize=(10,6))\n",
    "#creating scatterplot\n",
    "sns.scatterplot(ams.longitude,ams.latitude,hue=ams.neighbourhood).set_title(title)\n",
    "#moving legend\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb3d1b4",
   "metadata": {},
   "source": [
    "We can look at this in more detail by setting the `hue` as `room_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6f7de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Room type location per Neighbourhood'\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(ams.longitude,ams.latitude,hue=ams.room_type).set_title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38794a20",
   "metadata": {},
   "source": [
    "From this, we can see there is no particular pattern of where the type of room would be located; the shared rooms, for example, are equally spread across the city."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9177be88",
   "metadata": {},
   "source": [
    "Let's see what our data points look like on an interactive map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4501c4b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = folium.Map(\n",
    "    location = [52.377956, 4.897070],\n",
    "    tiles = 'Stamen Terrain',\n",
    "    zoom_start = 12             \n",
    "              )\n",
    "ams.apply(lambda x: folium.Circle([x.latitude, x.longitude], 50, fill=True).add_to(m).add_to(m),axis = 1)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f46a064",
   "metadata": {},
   "source": [
    "We can use a boxplot to look at the distribution of listing prices between neighbourhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9632471",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= 'neighbourhood'\n",
    "y= 'price'\n",
    "title = 'Price per Neighbourhood'\n",
    "\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "ax = sns.boxplot(x=x, y=y, data=ams)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f90cc1",
   "metadata": {},
   "source": [
    "Again, the many outliers mean that the boxplots are quite compressed. The majority of listings seem to be under $300, so we can focus on this in the next set of charts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6afcf6",
   "metadata": {},
   "source": [
    "## Price in Relation to Neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a923433",
   "metadata": {},
   "outputs": [],
   "source": [
    "x='neighbourhood'\n",
    "y='price'\n",
    "\n",
    "\n",
    "\n",
    "title = 'Price per neighbourhood for properties under $300'\n",
    "ams_filtered = ams.loc[ams['price'] < 300]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "sns.boxplot(x=x, y=y, data=ams_filtered, notch=True, showmeans=True,\n",
    "           meanprops={\"marker\":\"s\",\"markerfacecolor\":\"white\", \"markeredgecolor\":\"black\"})\n",
    "plt.title(title)\n",
    "plt.ioff()\n",
    "f\n",
    "title = 'Price per neighbourhood for properties more than $300'\n",
    "ams_filtered = ams.loc[ams['price'] > 300]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "sns.boxplot(x=x, y=y, data=ams_filtered, notch=False, showmeans=True,\n",
    "           meanprops={\"marker\":\"s\",\"markerfacecolor\":\"white\", \"markeredgecolor\":\"black\"})\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f56345",
   "metadata": {},
   "source": [
    "The white squares on each box plots demotes the mean. From this, we can see that Biljmer-Centrum is the cheapest neighbourhood to stay in according to the mean, while Oud-Oost is one of the most expensive. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9dab9a",
   "metadata": {},
   "source": [
    "## Price in Relation to Room Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11dce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Price per Room Type for Properties under $300'\n",
    "ams_filtered = ams.loc[ams['price'] < 300]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.boxplot(x='room_type', y='price', data=ams_filtered, notch=True, showmeans=True,\n",
    "           meanprops={\"marker\":\"s\",\"markerfacecolor\":\"white\", \"markeredgecolor\":\"black\"})\n",
    "plt.title(title)\n",
    "plt.ioff()\n",
    "\n",
    "title = 'Price per Room Type for Properties more than $300'\n",
    "ams_filtered = ams.loc[ams['price'] > 300]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.boxplot(x='room_type', y='price', data=ams_filtered, notch=False, showmeans=True,\n",
    "           meanprops={\"marker\":\"s\",\"markerfacecolor\":\"white\", \"markeredgecolor\":\"black\"})\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53de31bd",
   "metadata": {},
   "source": [
    "From this, we can note that there are very few shared rooms that cost more than \\\\$300, and that entire home/apartments are both the most expensive and have largest amount of spread of data points. For properties under \\\\$300,the mean price of an entire home/apartment is nearly \\\\$150, compared to a shared room, which is about \\\\$80."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae222f9",
   "metadata": {},
   "source": [
    "### Price in Relation to Number of Reviews per Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada3ecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'reviews_per_month'\n",
    "y = 'price'\n",
    "\n",
    "title = 'Price relation to number of reviews per month for Properties under $300'\n",
    "ams_filtered = ams.loc[(ams['price'] < 300)]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.scatterplot(x=x, y=y, data=ams_filtered)\n",
    "plt.title(title)\n",
    "plt.ioff()\n",
    "\n",
    "title = 'Price relation to number of reviews per month for Properties more than $300'\n",
    "ams_filtered = ams.loc[ams['price'] > 300]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.scatterplot(x=x, y=y, data=ams_filtered)\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e965c7",
   "metadata": {},
   "source": [
    "### Price in Relation to Number of Reviews per Month and Room Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637bf975",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'number_of_reviews'\n",
    "y = 'price'\n",
    "\n",
    "title = 'Price relation to number of review per month and Room Type for Properties under $300'\n",
    "ams_filtered = ams.loc[ams['price'] < 300]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.scatterplot(x=x, y=y, data=ams_filtered)\n",
    "plt.title(title)\n",
    "plt.ioff()\n",
    "\n",
    "title = 'Price relation to number of review per month and Room Type for Properties more than $300'\n",
    "ams_filtered = ams.loc[ams['price'] > 300]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.scatterplot(x=x, y=y, data=ams_filtered)\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908e8b3c",
   "metadata": {},
   "source": [
    "### Price in Relation to Minimum Nights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c8e345",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'minimum_nights'\n",
    "y = 'price'\n",
    "\n",
    "title = 'Price relation to minimum_nights for Properties under $300'\n",
    "ams_filtered = ams.loc[ams['price'] < 300]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.scatterplot(x=x, y=y, data=ams_filtered)\n",
    "plt.title(title)\n",
    "plt.ioff()\n",
    "\n",
    "title = 'Price relation to minimum_nights Properties more than $300'\n",
    "ams_filtered = ams.loc[ams['price'] > 300]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.scatterplot(x=x, y=y, data=ams_filtered)\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed84ca6e",
   "metadata": {},
   "source": [
    "### Price in Relation to Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc977df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'availability_365'\n",
    "y = 'price'\n",
    "\n",
    "title = 'Price relation to availability for Properties under $300'\n",
    "ams_filtered = ams.loc[ams['price'] < 300]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.scatterplot(x=x, y=y, data=ams_filtered)\n",
    "plt.title(title)\n",
    "plt.ioff()\n",
    "\n",
    "title = 'Price relation to availability for Properties more than $300'\n",
    "ams_filtered = ams.loc[ams['price'] > 300]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.scatterplot(x=x, y=y, data=ams_filtered)\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7651706d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exploratory Data Analysis (London)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7215ff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in London data\n",
    "ldn = pd.read_csv('airbnb_london/listings_summary.csv')\n",
    "ldn.set_index('id',inplace=True)\n",
    "ldn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b841f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196be7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_listings = len(ldn)\n",
    "num_hosts = len(ldn['host_id'].unique())\n",
    "\n",
    "print(f'The London data contains information about {num_listings} AirBnB listings from {num_hosts} hosts.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4865ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792fb6c8-9cd1-4adb-8aea-f25cb916de85",
   "metadata": {},
   "source": [
    "Like the Amsterdam data, most of the features are numeric, with some continuous floats such as `latitude` and `longitude`, and some integer variables such as `price`, `minimum_nights` and `availability_365`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab23a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unnecessary columns\n",
    "ldn.drop(['host_name','last_review', 'neighbourhood_group'], axis=1, inplace=True)\n",
    "# Visualize the first 5 rows\n",
    "ldn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f280872",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb24e159-7eca-4087-b302-bd99593ac6cc",
   "metadata": {},
   "source": [
    "The missing values in the `reviews_per_month` column correspond to rows where there are no reviews. As there have been no reviews left for this listing, the number of reviews per month cannot be calculated. This means that we can fill the null values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765a08b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing null values in reviews_per_month column with 0\n",
    "ldn.fillna({'reviews_per_month':0}, inplace=True)\n",
    "#replacing null values in name column with an empty string\n",
    "ldn['name'] = ldn[['name']].fillna((''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d5ee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#examine the dataset\n",
    "(ldn[['price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month',\n",
    "       'calculated_host_listings_count', 'availability_365']]\n",
    " .describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e237b8-d6d5-4613-9def-6cc7551e3f0a",
   "metadata": {},
   "source": [
    "From the table above, we can see that the minimum price for a room is 0, the same as what happened above for the Amsterdam data. We will only use values that are more than 0. Similarly, we have a maximum value of 1125 for `minimum_nights`, so we will cut the dataset so it only shows rows where the value for `minimum_nights` is less than 31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1818d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only include listings where price > 0\n",
    "ldn = ldn.loc[ldn['price'] > 0]\n",
    "#only include listings where minimum_nights < 31\n",
    "ldn = ldn.loc[ldn['minimum_nights'] < 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2c2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abea07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataset for the correlation matrix, removing unnecessary variables\n",
    "corr_ldn = ldn[['price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month',\n",
    "       'calculated_host_listings_count', 'availability_365']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dfdebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = corr_ldn.quantile(q=.25)\n",
    "Q3 = corr_ldn.quantile(q=.75)\n",
    "IQR = corr_ldn.apply(stats.iqr)\n",
    "\n",
    "ldn_no_outliers = corr_ldn[~((corr_ldn < (Q1-1.5*IQR)) | (corr_ldn > (Q3+1.5*IQR))).any(axis=1)]\n",
    "ldn_no_outliers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4326e149-8d0d-4088-8a08-9b06e9cc6746",
   "metadata": {},
   "source": [
    "We can now use some basic Natural Language Processing (NLP) to create a word cloud of the most common words and phrases used in listings names for places in London. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073e7bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn_name = ldn['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88caef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(str(each) for each in ldn_name)\n",
    "# Create and generate a word cloud image:\n",
    "wordcloud = WordCloud(max_words=200, background_color=\"white\").generate(text)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.figure(figsize=(15,10))\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='Bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6cfb4a-a6b3-4f0b-acfb-856a2b7fb790",
   "metadata": {},
   "source": [
    "From this word cloud, we could assume that listings are most popular in Central London, along with double room/bedroom. The words 'apartment' and 'beautiful' are prominent in this word cloud, which were were words that were common in the Amsterdam word cloud.\n",
    "\n",
    "A couple of place names are mentioned here, for example Hyde Park, Canary Wharf, Shoreditch and Notting Hill - it seems hosts are keen to advertise their closeness to these popular destinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f83f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "text = ''.join([i for i in text if not i.isdigit()])\n",
    "text = text.lower()\n",
    "text = remove_stopwords(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d817fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the Counter instance `most_common` call to a variable:\n",
    "word_frequency = Counter(\"\".join(text).split()).most_common(10)\n",
    "\n",
    "# `most_common` returns a list of (word, count) tuples\n",
    "words = [word for word, _ in word_frequency]\n",
    "counts = [counts for _, counts in word_frequency]\n",
    "\n",
    "plt.bar(words, counts, color = \"#ff8882\")\n",
    "plt.title(\"10 most frequent tokens in description\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Words\")\n",
    "xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185a1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "subplot(2,3,1)\n",
    "sns.distplot(ldn['price'])\n",
    "\n",
    "subplot(2,3,2)\n",
    "sns.distplot(ldn['minimum_nights'])\n",
    "\n",
    "subplot(2,3,3)\n",
    "sns.distplot(ldn['number_of_reviews'])\n",
    "\n",
    "subplot(2,3,4)\n",
    "sns.distplot(ldn['reviews_per_month'])\n",
    "\n",
    "subplot(2,3,5)\n",
    "sns.distplot(ldn['calculated_host_listings_count'])\n",
    "\n",
    "subplot(2,3,6)\n",
    "sns.distplot(ldn['availability_365'])\n",
    "\n",
    "\n",
    "plt.tight_layout() # avoid overlap of plots\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0f1bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "\n",
    "\n",
    "subplot(2,3,1)\n",
    "sns.boxplot(y = ldn['price']) \n",
    "\n",
    "subplot(2,3,2)\n",
    "sns.boxplot(y = ldn['minimum_nights'])\n",
    "\n",
    "subplot(2,3,3)\n",
    "sns.boxplot(y = ldn['number_of_reviews'])\n",
    "\n",
    "subplot(2,3,4)\n",
    "sns.boxplot(y = ldn['reviews_per_month'])\n",
    "\n",
    "subplot(2,3,6)\n",
    "sns.boxplot(y = ldn['availability_365'])\n",
    "\n",
    "plt.tight_layout() # avoid overlap of plots\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05c7aac-d55c-4c4a-8bae-b5760d3a7a3d",
   "metadata": {},
   "source": [
    "Similar to the Amsterdam boxplots, there is a large amount of outliers present for the London data. The box plots for `price` and `number_of_reviews` are very squashed so it is quite hard to read data from these. One major difference between the Amsterdam and London boxplots is that there are no outliers present on the `availabilty_365` box plot for London. Amsterdam's median for `availability_365` was about 10, whereas for London it is about 60. Likewise, Amsterdam's upper quartile is about 70, compared to London's which is much higher at about 250. This means that hosts in London tend to have a much higher availability out of the 365 days in the year compared to Amsterdam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da89ba4-6fee-45f1-b472-a391d12648f4",
   "metadata": {},
   "source": [
    "We can also create a bar chart to see the counts of values for `room_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23343c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Properties per Room Type'\n",
    "sns.countplot(ldn['room_type'])\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a9374f-eff5-451a-93ca-58c8bd49f45c",
   "metadata": {},
   "source": [
    "Another room type has appeared that wasn't present in the Amsterdam data; hosts have offered hotel rooms. However, these and shared rooms take up a very small proportion of the total listings - entire homes/apartments and private rooms are much more popular. Like Amsterdam, entire homes/apartments are the most popular, with close to 5000 being listed on Airbnb in London.\n",
    "\n",
    "We can also look at the count of listings for each neighbourhood in London."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c332ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Properties per Neighbourhood Group'\n",
    "ax = sns.countplot(ldn['neighbourhood'])\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "rcParams['figure.figsize'] = 25,15\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cdd9ad-b2da-415b-a972-60eac9ac27c5",
   "metadata": {},
   "source": [
    "We can see that the three most popular neighbourhoods to stay in in London are Westminster, Town Hamlets and Hackney, whereas the three least popular are Havering, Bexley and Sutton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7374646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "title = 'Correlation matrix of numerical variables'\n",
    "sns.heatmap(corr_ldn.corr(), annot=True, square=True, cmap='RdBu')\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c445d459-a16b-4c0e-8037-9cb15d1e36f0",
   "metadata": {},
   "source": [
    "This correlation matrix shares quite a few things in common with the Amsterdam one. Again, none of the variables are particularly correlated (nothing lower than -0.2). The most negative correlation is betwen `reviews_per_month` and `minimum_nights`. Like the Amsterdam dataset, there is a positive correlation of roughly 0.6 between `reviews_per_month` and `number_of_reviews`. Also, several other positive correlations can be seen between `availability_365` and other variables such as `price` and `number_of_reviews`, but less so in this matrix compared with the Amsterdam one. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc0a932-e862-460d-85ce-2365602efa61",
   "metadata": {},
   "source": [
    "Next, we can see where listings are in relation to their latitude and longitude. Using a scatterplot will create a map-like image for us to see where neighbourhoods are positioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ad9221",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Neighbourhood Location'\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(ldn.longitude,ldn.latitude,hue=ldn.neighbourhood).set_title(title)\n",
    "# moving legend\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc28b5da-7882-4d58-9ddf-a0c4e0be7a5c",
   "metadata": {},
   "source": [
    "We can look at this in more detail by setting the hue as `room_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12410adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Room type location per Neighbourhood'\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(ldn.longitude,ldn.latitude,hue=ldn.room_type).set_title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a93903f-67bd-4b8c-b756-baba5cc045d4",
   "metadata": {},
   "source": [
    "There is slightly more of a pattern seen here than for the Amsterdam data. There are no hotel rooms or shared rooms in central London, and although both entire homes and private rooms are listed in abundance across London, entire homes seem to be more promininent in central London.\n",
    "\n",
    "Now we can see what our data points look like on an interactive map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb76ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = folium.Map(\n",
    "    location = [51.509865, -0.118092],\n",
    "    tiles = 'Stamen Terrain',\n",
    "    zoom_start = 12             \n",
    "              )\n",
    "ldn.apply(lambda x: folium.Circle([x.latitude, x.longitude], 50, fill=True).add_to(m).add_to(m),axis = 1)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4044a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= 'neighbourhood'\n",
    "y= 'price'\n",
    "title = 'Price per Neighbourhood'\n",
    "\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "ax = sns.boxplot(x=x, y=y, data=ldn)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376671a9-efb3-4f7f-88e7-f11cda058720",
   "metadata": {},
   "source": [
    "Again, the many outliers mean that the boxplots are very compressed. The majority of listings seem to be under $200, so we can focus on this in the next set of charts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e5e81b-a372-4814-91bb-d12fa66eae80",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Price in Relation to Neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6a58f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x='neighbourhood'\n",
    "y='price'\n",
    "\n",
    "title = 'Price per neighbourhood for properties under $200'\n",
    "ldn_filtered = ldn.loc[ldn['price'] < 200]\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "sns.boxplot(x=x, y=y, data=ldn_filtered, notch=True, showmeans=True,\n",
    "           meanprops={\"marker\":\"s\",\"markerfacecolor\":\"white\", \"markeredgecolor\":\"black\"})\n",
    "plt.title(title)\n",
    "plt.ioff()\n",
    "f\n",
    "title = 'Price per neighbourhood for properties more than $200'\n",
    "ldn_filtered = ldn.loc[ldn['price'] > 200]\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "sns.boxplot(x=x, y=y, data=ldn_filtered, notch=False, showmeans=True,\n",
    "           meanprops={\"marker\":\"s\",\"markerfacecolor\":\"white\", \"markeredgecolor\":\"black\"})\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef42335-8bf5-4e66-b1e0-6b190ffd15d0",
   "metadata": {},
   "source": [
    "The white squares on each box plots demotes the mean. From this, we can see that if someone was looking for a listing under \\\\$200, the City of London is by far the most expensive borough (neighbourhood) to stay in, with a mean of around \\\\$130 per night - over double the mean cost of a night in Croydon (\\\\$60). When looking at the boxplots for listings over \\\\$200, we can see in more detail that boroughs like Camden and Westminster have many outliers. For example, the most expensive listing in Westminster is $10,000 a night. Whether this is a mistake or a genuine listing price, we can't be sure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05756b2f-647c-448e-b15b-915f1c7cb84f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prices in Relation to Room Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df801f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Price per Room Type for Properties under $200'\n",
    "ldn_filtered = ldn.loc[ldn['price'] < 200]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.boxplot(x='room_type', y='price', data=ldn_filtered, notch=True, showmeans=True,\n",
    "           meanprops={\"marker\":\"s\",\"markerfacecolor\":\"white\", \"markeredgecolor\":\"black\"})\n",
    "plt.title(title)\n",
    "plt.ioff()\n",
    "\n",
    "title = 'Price per Room Type for Properties more than $200'\n",
    "ldn_filtered = ldn.loc[ldn['price'] > 200]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.boxplot(x='room_type', y='price', data=ldn_filtered, notch=False, showmeans=True,\n",
    "           meanprops={\"marker\":\"s\",\"markerfacecolor\":\"white\", \"markeredgecolor\":\"black\"})\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff32a0d-7591-4273-a01c-43efcea837b9",
   "metadata": {},
   "source": [
    "From this, we can note that again, shared rooms tend to be the cheapest type of room to rent. For listings under \\\\$200, the mean for entire home/apartments and hotel rooms is almost exactly the same (around $110), but hotel rooms have a larger spread of prices and a slightly higher median than entire home/apartments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd2908d-7332-4b9a-94a2-c65bb3d0882e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Price in Relation to Reviews per Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56299c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'reviews_per_month'\n",
    "y = 'price'\n",
    "\n",
    "title = 'Price relation to number of review per month for Properties under $175'\n",
    "ldn_filtered = ldn.loc[(ldn['price'] < 175) & (ldn['reviews_per_month'] < 30)]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.scatterplot(x=x, y=y, data=ldn_filtered)\n",
    "plt.title(title)\n",
    "plt.ioff()\n",
    "\n",
    "title = 'Price relation to number of review per month for Properties more than $175'\n",
    "ldn_filtered = ldn.loc[ldn['price'] > 175]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.scatterplot(x=x, y=y, data=ldn_filtered)\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4f3f39-2271-45ad-bda1-ebe513f62d3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Price in Relation to Number of Reviews per Month and Room Type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c737f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'number_of_reviews'\n",
    "y = 'price'\n",
    "\n",
    "title = 'Price relation to number of review per month and Room Type for Properties under $175'\n",
    "ldn_filtered = ldn.loc[ldn['price'] < 175]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.scatterplot(x=x, y=y, data=ldn_filtered)\n",
    "plt.title(title)\n",
    "plt.ioff()\n",
    "\n",
    "title = 'Price relation to number of review per month and Room Type for Properties more than $175'\n",
    "ldn_filtered = ldn.loc[ldn['price'] > 175]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.scatterplot(x=x, y=y, data=ldn_filtered)\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ae0063-c03b-4c56-8653-e9af76cfb12e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Price in Relation to Minimum Nights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef168e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'minimum_nights'\n",
    "y = 'price'\n",
    "\n",
    "title = 'Price relation to minimum_nights for Properties under $175'\n",
    "ldn_filtered = ldn.loc[ldn['price'] < 175]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.scatterplot(x=x, y=y, data=ldn_filtered)\n",
    "plt.title(title)\n",
    "plt.ioff()\n",
    "\n",
    "title = 'Price relation to minimum_nights Properties more than $175'\n",
    "ldn_filtered = ldn.loc[ldn['price'] > 175]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.scatterplot(x=x, y=y, data=ldn_filtered)\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7df982f-f8af-453c-ba42-1dbc2ac1dbe9",
   "metadata": {},
   "source": [
    "## Price in Relation to Availability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e02285",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'availability_365'\n",
    "y = 'price'\n",
    "\n",
    "title = 'Price relation to availability for Properties under $175'\n",
    "ldn_filtered = ldn.loc[ldn['price'] < 175]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.scatterplot(x=x, y=y, data=ldn_filtered)\n",
    "plt.title(title)\n",
    "plt.ioff()\n",
    "\n",
    "title = 'Price relation to availability for Properties more than $175'\n",
    "ldn_filtered = ldn.loc[ldn['price'] > 175]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.scatterplot(x=x, y=y, data=ldn_filtered)\n",
    "plt.title(title)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97fabf2-53c1-4bde-9a11-a6a3cab659e1",
   "metadata": {},
   "source": [
    "# What hosts' behaviors or profiles would influence AirBNB tenants reviews in both London and Amsterdam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc8712d-c4b8-450f-81e7-59038476b4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ldn = pd.read_csv('/Users/georginadangerfield/Downloads/assignment/airbnb_london/listings.csv')\n",
    "df_ams = pd.read_csv('/Users/georginadangerfield/Downloads/assignment/airbnb_madrid/listings_detailed.csv')\n",
    "\n",
    "num_rows_ldn = df_ldn.shape[0]\n",
    "num_cols_ldn = df_ldn.shape[1]\n",
    "\n",
    "num_rows_ams = df_ams.shape[0]\n",
    "num_cols_ams = df_ams.shape[1]\n",
    "\n",
    "most_missing_cols_ldn = set(df_ldn.columns[df_ldn.isnull().mean() > 0.75])\n",
    "most_missing_cols_ams = set(df_ams.columns[df_ams.isnull().mean() > 0.75])\n",
    "\n",
    "print(num_rows_ldn, num_cols_ldn, num_rows_ams, num_cols_ams)\n",
    "print(most_missing_cols_ldn, most_missing_cols_ams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ba4f7f-cd5a-4801-8bed-928dad3738cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Data Cleaning function for London\n",
    "def clean_dataset_ldn(df):\n",
    "    '''\n",
    "    INPUT\n",
    "    df - pandas dataframe containing data \n",
    "    \n",
    "    OUTPUT\n",
    "    new_df - cleaned dataset, which contains:\n",
    "    1. string containing price are converted into numbers;\n",
    "    2. missing values are imputed with mean or mode or drop\n",
    "    '''\n",
    "    \n",
    "    useless_columns = ['access', 'interaction', 'house_rules','name', 'host_name', 'square_feet', 'id', 'host_id','summary', 'space', 'description', 'neighborhood_overview', 'notes', \n",
    "                       'host_since', 'host_location', 'host_about', 'host_neighbourhood', 'host_total_listings_count', 'street', 'neighbourhood', \n",
    "                       'minimum_nights', 'maximum_nights', 'city', 'zipcode', 'smart_location', 'latitude', \n",
    "                       'longitude', 'is_location_exact', 'weekly_price', 'monthly_price', 'require_guest_profile_picture', \n",
    "                       'require_guest_phone_verification', 'calculated_host_listings_count', 'availability_30', 'availability_60', 'availability_90', \n",
    "                       'availability_365', 'calendar_updated','transit', 'medium_url', 'xl_picture_url']\n",
    "    \n",
    "    # if all values are unique in this column, like ID, or if the values are url links, then drop it\n",
    "    for col in df.columns:\n",
    "        if len(df[col].unique()) == 1:\n",
    "            df.drop(col, inplace=True, axis=1)\n",
    "        if ('url' in col):\n",
    "            df.drop(col, inplace=True, axis=1)\n",
    "        if col in useless_columns:\n",
    "            df.drop(col, inplace=True, axis=1)\n",
    "    \n",
    "    # generate review columns\n",
    "    review_columns = []\n",
    "    for col in df:\n",
    "        if 'review' in col:\n",
    "            review_columns.append(col)\n",
    "    \n",
    "    \n",
    "    #convert all related 'price' columns values from string to number\n",
    "    df['price'] = df['price'].astype(str).str.replace(\"[$, ]\", \"\").astype(\"float\")\n",
    "    df['security_deposit'] = df['security_deposit'].astype(str).str.replace(\"[$, ]\", \"\").astype(\"float\")\n",
    "    df['cleaning_fee'] = df['cleaning_fee'].astype(str).str.replace(\"[$, ]\", \"\").astype(\"float\")\n",
    "    df['extra_people'] = df['extra_people'].astype(str).str.replace(\"[$, ]\", \"\").astype(\"float\")\n",
    "    #convert all percentage columns values to float number\n",
    "    df['host_response_rate'] = df['host_response_rate'].astype(str).str.replace(\"[%, ]\", \"\").astype(\"float\")/100\n",
    "    #generate new review metric\n",
    "    df['new_review_metric'] = df['reviews_per_month'] * df['review_scores_rating']/100\n",
    "    #drop original review columns\n",
    "    df = df.drop(review_columns, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2620972-f95d-46ac-b004-627b8282c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Data Cleaning function for Amsterdam\n",
    "def clean_dataset_ams(df):\n",
    "    '''\n",
    "    INPUT\n",
    "    df - pandas dataframe containing data \n",
    "    \n",
    "    OUTPUT\n",
    "    new_df - cleaned dataset, which contains:\n",
    "    1. string containing price are converted into numbers;\n",
    "    2. missing values are imputed with mean or mode or drop\n",
    "    '''\n",
    "    \n",
    "    useless_columns = ['access', 'interaction', 'house_rules','name', 'host_name', 'square_feet', 'id', 'host_id','summary', 'space', 'description', 'neighborhood_overview', 'notes', \n",
    "                       'host_since', 'host_location', 'host_about', 'host_neighbourhood', 'host_total_listings_count', 'street', 'neighbourhood', \n",
    "                       'minimum_nights', 'maximum_nights', 'city', 'zipcode', 'smart_location', 'latitude', \n",
    "                       'longitude', 'is_location_exact', 'weekly_price', 'monthly_price', 'require_guest_profile_picture', \n",
    "                       'require_guest_phone_verification', 'calculated_host_listings_count', 'availability_30', 'availability_60', 'availability_90', \n",
    "                       'availability_365', 'transit', 'medium_url', 'xl_picture_url',\n",
    "                      'host_acceptance_rate', 'xl_picture_url', 'host_acceptance_rate']\n",
    "    \n",
    "    # if all values are unique in this column, like ID, or if the values are url links, then drop it\n",
    "    for col in df.columns:\n",
    "        if len(df[col].unique()) == 1:\n",
    "            df.drop(col, inplace=True, axis=1)\n",
    "        if ('url' in col):\n",
    "            df.drop(col, inplace=True, axis=1)\n",
    "        if col in useless_columns:\n",
    "            df.drop(col, inplace=True, axis=1)\n",
    "    \n",
    "    # generate review columns\n",
    "    review_columns = []\n",
    "    for col in df:\n",
    "        if 'review' in col:\n",
    "            review_columns.append(col)\n",
    "    \n",
    "    \n",
    "    #convert all related 'price' columns values from string to number\n",
    "    df['price'] = df['price'].astype(str).str.replace(\"[$, ]\", \"\").astype(\"float\")\n",
    "    #convert all percentage columns values to float number\n",
    "    df['host_response_rate'] = df['host_response_rate'].astype(str).str.replace(\"[%, ]\", \"\").astype(\"float\")/100\n",
    "    #generate new review metric\n",
    "    df['new_review_metric'] = df['reviews_per_month'] * df['review_scores_rating']/100\n",
    "    #drop original review columns\n",
    "    df = df.drop(review_columns, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30e6f25-bb01-4846-8d52-3ec30dd7080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data cleaning functions above to clean dataset\n",
    "clean_df_ldn = clean_dataset_ldn(df_ldn)\n",
    "clean_df_ams = clean_dataset_ams(df_ams)\n",
    "clean_df_ldn.drop('state', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7099a95d-5b00-4a67-918c-020de7acdc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def element_len(df, colname):\n",
    "    coliloc = df.columns.get_loc(colname)\n",
    "    \n",
    "    for i, row in enumerate(df[colname]):\n",
    "        df.iloc[i, coliloc] = row.replace('[', '').replace(\"'\", '').replace(\"]\", '').replace('\"', '').replace('{', '').replace('}', '').replace(' ','')\n",
    "        df.iloc[i, coliloc] = len(df.iloc[i, coliloc].split(','))\n",
    "    return df\n",
    "\n",
    "def create_dummy_df(df, dummy_na):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with categorical variables you want to dummy\n",
    "    cat_cols - list of strings that are associated with names of the categorical columns\n",
    "    dummy_na - Bool holding whether you want to dummy NA vals of categorical columns or not\n",
    "    \n",
    "    OUTPUT:\n",
    "    df - a new dataframe that has the following characteristics:\n",
    "            1. contains all columns that were not specified as categorical\n",
    "            2. removes all the original columns in cat_cols\n",
    "            3. dummy columns for each of the categorical columns in cat_cols\n",
    "            4. if dummy_na is True - it also contains dummy columns for the NaN values\n",
    "            5. Use a prefix of the column name with an underscore (_) for separating \n",
    "    '''\n",
    "    # Dummy the categorical variables\n",
    "    cat_cols = ['host_response_time', 'host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'instant_bookable', 'cancellation_policy']\n",
    "\n",
    "    for col in  cat_cols:\n",
    "        try:\n",
    "            # for each cat add dummy var, drop original column\n",
    "            df = pd.concat([df.drop(col, axis=1), pd.get_dummies(df[col], prefix=col, prefix_sep='_', drop_first=True, dummy_na=dummy_na)], axis=1)\n",
    "        except:\n",
    "            continue\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1b449e-b4e2-4ab0-a78c-66789da54438",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_ldn = element_len(clean_df_ldn, 'amenities')\n",
    "clean_df_ldn = element_len(clean_df_ldn, 'host_verifications')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596e9b38-dca4-4a7f-bb49-ea89e8f9a20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_ams = element_len(clean_df_ams, 'amenities')\n",
    "clean_df_ams = element_len(clean_df_ams, 'host_verifications')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae81c262-9f57-4aad-ba46-9a0a80a913f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_ldn = create_dummy_df(clean_df_ldn, dummy_na=False)\n",
    "clean_df_ams = create_dummy_df(clean_df_ams, dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5216576-96bd-48a6-9575-34f59f0a651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in clean_df_ams:\n",
    "    if col not in clean_df_ldn:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc69e3f-f821-46cf-98d1-e594bda83e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a new behavior_review dataframe for analysis\n",
    "behavior_review_ldn_cols =  ['host_response_rate',\n",
    "                        'host_response_time_within a day',\n",
    "                        'host_response_time_within a few hours',\n",
    "                        'host_response_time_within an hour',\n",
    "                        'host_has_profile_pic_t', \n",
    "                        'host_identity_verified_t', \n",
    "                        'host_is_superhost_t', \n",
    "                        'instant_bookable_t', \n",
    "                        'cancellation_policy_moderate',\n",
    "                        'cancellation_policy_strict',\n",
    "                        'cancellation_policy_super_strict_30',\n",
    "                        'amenities',\n",
    "                        'host_verifications',\n",
    "                        'guests_included', 'extra_people', 'price']\n",
    "\n",
    "behavior_review_ldn = clean_df_ldn[behavior_review_ldn_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87319327-bb87-4aad-b386-9f42d7bda1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a new behavior_review dataframe for analysis\n",
    "behavior_review_ams_cols =  ['host_response_rate',\n",
    "                        'host_response_time_within a day',\n",
    "                        'host_response_time_within a few hours',\n",
    "                        'host_response_time_within an hour',\n",
    "                        'host_has_profile_pic_t', \n",
    "                        'host_identity_verified_t', \n",
    "                        'host_is_superhost_t', \n",
    "                        'instant_bookable_t',\n",
    "                        'amenities',\n",
    "                        'host_verifications','price']\n",
    "\n",
    "behavior_review_ams = clean_df_ams[behavior_review_ams_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c957c3-5ab9-4056-8fb2-bf280c850af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "corr = behavior_review_ldn.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "plt.rcParams['figure.figsize'] = [11, 9]\n",
    "sns.heatmap(corr, mask=mask, annot = True, fmt='.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b8f3eb-340a-46c8-871e-7f2e8b1f020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "corr = behavior_review_ams.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "plt.rcParams['figure.figsize'] = [11, 9]\n",
    "sns.heatmap(corr, mask=mask, annot = True, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c83a35-f0e2-46bf-97b7-785eda954654",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57cff9d-4e1c-47b1-b05c-691a6c2e6ca6",
   "metadata": {},
   "source": [
    "I will be performing the following in order to answer the research questions for this project:\n",
    "\n",
    "- Multiple linear regression\n",
    "- Random forest\n",
    "- OLS Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8de4d9c-a35a-4baa-8f78-707554e5cf00",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression (Amsterdam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a47d061-940c-47f0-a7a2-445e861521d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ams.drop(['name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f449820a-d891-4c67-a0c7-34f47a36b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log10 transformation\n",
    "ams.minimum_nights += 0.000000001\n",
    "ams['minimum_nights'] = np.log10(ams['minimum_nights'])\n",
    "ams.number_of_reviews += 0.000000001\n",
    "ams['number_of_reviews'] = np.log10(ams['number_of_reviews'])\n",
    "ams.reviews_per_month += 0.000000001\n",
    "ams['reviews_per_month'] = np.log10(ams['reviews_per_month'])\n",
    "ams.calculated_host_listings_count += 0.000000001\n",
    "ams['calculated_host_listings_count'] = np.log10(ams['calculated_host_listings_count'])\n",
    "ams.availability_365 += 0.000000001\n",
    "ams['availability_365'] = np.log10(ams['availability_365'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12bd58b-2243-41c7-9a5b-1b8679ae4856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "ams = pd.get_dummies(ams, columns=['room_type'], drop_first=True)\n",
    "ams = pd.get_dummies(ams, columns=['neighbourhood'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4284c048-7c1f-4025-8b10-8a7d1ac9ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset for prices more than $300\n",
    "ams_filtered_high = ams.loc[(ams['price'] > 300)]\n",
    "# Filter the dataset for prices less that $300\n",
    "ams_filtered_low = ams.loc[(ams['price'] < 300)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd64918-9778-49cf-a782-d4c9ff8f7323",
   "metadata": {},
   "source": [
    "### Modelling lower price dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecdf43b-3416-41ca-bd14-bc01e6800650",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ams_filtered_low.drop('price', axis=1).values\n",
    "y = ams_filtered_low['price'].values\n",
    "y = np.log10(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecca7ba-04cf-48aa-99b8-95be06a6a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "# Fitting Multiple Linear Regression to the Training set\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b691668c-edc8-4e4f-8bbd-0fc316b94627",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual': np.round(10 ** y_test, 0), \n",
    "                   'Predicted': np.round(10 ** y_pred, 0)})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292f6877-21e4-46eb-ba5f-13900173275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Price mean:', np.round(np.mean(y), 2))  \n",
    "print('Price std:', np.round(np.std(y), 2))\n",
    "print('RMSE:', np.round(np.sqrt(metrics.mean_squared_error(y_test, lr.predict(X_test))), 2))\n",
    "print('R2 score train:', np.round(r2_score(y_train, lr.predict(X_train), multioutput='variance_weighted'), 2))\n",
    "print('R2 score test:', np.round(r2_score(y_test, lr.predict(X_test), multioutput='variance_weighted'), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0844722f-0037-4df8-9ccd-a04ba67e4228",
   "metadata": {},
   "source": [
    "RMSE is close to 0 so suggests high accuracy\n",
    "\n",
    "However, the R2 score is not very close to 1 so suggests the accuracy might not be as good as first thought (Malekinezhad et al., 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5cb1dc-ab67-41e6-9384-b2d260847e85",
   "metadata": {},
   "source": [
    "### Modelling higher price dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126405c8-6318-4f61-b3bc-4e9ae1f9ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ams_filtered_high.drop('price', axis=1).values\n",
    "y = ams_filtered_high['price'].values\n",
    "y = np.log10(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3080d8-d114-4a3a-9e52-163694f27c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "# Fitting Multiple Linear Regression to the Training set\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e44805-17a8-459b-911d-758dd4e5e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual': np.round(10 ** y_test, 0), \n",
    "                   'Predicted': np.round(10 ** y_pred, 0)})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b7b31b-7dc4-44b4-8479-01af2a7651d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Price mean:', np.round(np.mean(y), 2))  \n",
    "print('Price std:', np.round(np.std(y), 2))\n",
    "print('RMSE:', np.round(np.sqrt(metrics.mean_squared_error(y_test, lr.predict(X_test))), 2))\n",
    "print('R2 score train:', np.round(r2_score(y_train, lr.predict(X_train), multioutput='variance_weighted'), 2))\n",
    "print('R2 score test:', np.round(r2_score(y_test, lr.predict(X_test), multioutput='variance_weighted'), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4552ed-9647-4025-80ff-08490e828b9b",
   "metadata": {},
   "source": [
    "RMSE suggests high accuracy of this model as score is close to 0, but R2 score suggests otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d09d5c-a993-4e75-b690-2566ac243c41",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression (London)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3312de64-76db-4efb-9d7d-40f64622e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn.drop(['name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e31491-e9ad-4b01-a3ab-0839c6d71c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log10 transformation\n",
    "ldn.minimum_nights += 0.000000001\n",
    "ldn['minimum_nights'] = np.log10(ldn['minimum_nights'])\n",
    "ldn.number_of_reviews += 0.000000001\n",
    "ldn['number_of_reviews'] = np.log10(ldn['number_of_reviews'])\n",
    "ldn.reviews_per_month += 0.000000001\n",
    "ldn['reviews_per_month'] = np.log10(ldn['reviews_per_month'])\n",
    "ldn.calculated_host_listings_count += 0.000000001\n",
    "ldn['calculated_host_listings_count'] = np.log10(ldn['calculated_host_listings_count'])\n",
    "ldn.availability_365 += 0.000000001\n",
    "ldn['availability_365'] = np.log10(ldn['availability_365'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2b70e6-4d31-4e31-a27f-902c00a1d008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "ldn = pd.get_dummies(ldn, columns=['room_type'], drop_first=True)\n",
    "ldn = pd.get_dummies(ldn, columns=['neighbourhood'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f99925e-0b5d-4ca5-bded-d249ff703548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset for prices more than $300\n",
    "ldn_filtered_high = ldn.loc[(ldn['price'] > 300)]\n",
    "# Filter the dataset for prices less that $300\n",
    "ldn_filtered_low = ldn.loc[(ldn['price'] < 300)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003edb48-6adc-4480-ae48-6264874eb616",
   "metadata": {},
   "source": [
    "### Modelling lower price dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3d4e94-69dc-4e3e-b353-7bef2896a237",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ldn_filtered_low.drop('price', axis=1).values\n",
    "y = ldn_filtered_low['price'].values\n",
    "y = np.log10(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d04fa52-086a-4205-a9b8-61bc1da1af08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "# Fitting Multiple Linear Regression to the Training set\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6019464-f7bc-409e-9926-73a9a6b13856",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual': np.round(10 ** y_test, 0), \n",
    "                   'Predicted': np.round(10 ** y_pred, 0)})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f66af3-0e78-4056-ae4e-3d6992547cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Price mean:', np.round(np.mean(y), 2))  \n",
    "print('Price std:', np.round(np.std(y), 2))\n",
    "print('RMSE:', np.round(np.sqrt(metrics.mean_squared_error(y_test, lr.predict(X_test))), 2))\n",
    "print('R2 score train:', np.round(r2_score(y_train, lr.predict(X_train), multioutput='variance_weighted'), 2))\n",
    "print('R2 score test:', np.round(r2_score(y_test, lr.predict(X_test), multioutput='variance_weighted'), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c58d1e0-ed0a-464e-960f-4b2433bc18b9",
   "metadata": {},
   "source": [
    "Relatively high accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09757e17-6d39-412e-be54-7601cb1a408b",
   "metadata": {},
   "source": [
    "### Modelling higher price dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cc2d38-3f66-45dc-bab2-05b6fdab5c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ldn_filtered_high.drop('price', axis=1).values\n",
    "y = ldn_filtered_high['price'].values\n",
    "y = np.log10(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4364573-13c2-43f3-af3d-21c1afc741ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "# Fitting Multiple Linear Regression to the Training set\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd50caa8-aad7-4f45-b66f-27686b2d0ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual': np.round(10 ** y_test, 0), \n",
    "                   'Predicted': np.round(10 ** y_pred, 0)})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66df57f-c329-4ada-9980-7341aa4d07c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Price mean:', np.round(np.mean(y), 2))  \n",
    "print('Price std:', np.round(np.std(y), 2))\n",
    "print('RMSE:', np.round(np.sqrt(metrics.mean_squared_error(y_test, lr.predict(X_test))), 2))\n",
    "print('R2 score train:', np.round(r2_score(y_train, lr.predict(X_train), multioutput='variance_weighted'), 2))\n",
    "print('R2 score test:', np.round(r2_score(y_test, lr.predict(X_test), multioutput='variance_weighted'), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a059565e-1007-42ec-a2c3-841316c2bd9e",
   "metadata": {},
   "source": [
    "Poor accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b068c85b-eb2b-41ee-994d-063611c1b598",
   "metadata": {},
   "source": [
    "# Random Forest Regression (Amsterdam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b172258c-75ca-41ff-93fa-f49db952f7da",
   "metadata": {},
   "source": [
    "### Random Forest - lower price dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52918080-9f0d-4812-a641-b4738cae1ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X = ams_filtered_low.drop('price', axis=1).values\n",
    "y = ams_filtered_low['price'].values\n",
    "y = np.log10(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66c7c6f-3386-46f2-bcb9-26e1f2e9f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b63a15-560e-4275-8cfa-609697abf6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(max_depth=8, n_estimators = 100, random_state = 0)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44095a47-f7a2-4e02-8b4e-713b97b6aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual': np.round(10 ** y_test, 0), \n",
    "                   'Predicted': np.round(10 ** y_pred, 0)})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46197896-f80c-49aa-9397-2d7fc3b47805",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Price mean:', np.round(np.mean(y), 2))  \n",
    "print('Price std:', np.round(np.std(y), 2))\n",
    "print('RMSE:', np.round(np.sqrt(metrics.mean_squared_error(y_test, rfr.predict(X_test))), 2))\n",
    "print('R2 score train:', np.round(r2_score(y_train, rfr.predict(X_train), multioutput='variance_weighted'), 2))\n",
    "print('R2 score test:', np.round(r2_score(y_test, rfr.predict(X_test), multioutput='variance_weighted'), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e0a9e-9472-4631-84bb-0846cc83b249",
   "metadata": {},
   "source": [
    "Good accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77103c1-74a4-43ac-a526-26056ad32269",
   "metadata": {},
   "source": [
    "### Random Forest - higher price dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ceac9e-ef83-4dac-b72e-59dd4adf52ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X = ams_filtered_high.drop('price', axis=1)\n",
    "y = ams_filtered_high['price']\n",
    "y = np.log10(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a394dc70-b88e-4926-b86e-c8d163c5d12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745c692a-ba26-40de-b0ed-a694b54bcf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(max_depth=8, n_estimators = 100, random_state = 0)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0da54bf-ad0b-4a99-8464-7a3e8826f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual': np.round(10 ** y_test, 0), \n",
    "                   'Predicted': np.round(10 ** y_pred, 0)})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2ecd90-9d9d-43ec-a804-c9636af7affb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Price mean:', np.round(np.mean(y), 2))  \n",
    "print('Price std:', np.round(np.std(y), 2))\n",
    "print('RMSE:', np.round(np.sqrt(metrics.mean_squared_error(y_test, rfr.predict(X_test))), 2))\n",
    "print('R2 score train:', np.round(r2_score(y_train, rfr.predict(X_train), multioutput='variance_weighted'), 2))\n",
    "print('R2 score test:', np.round(r2_score(y_test, rfr.predict(X_test), multioutput='variance_weighted'), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c80efd-d533-4d75-b5a9-94a6be383921",
   "metadata": {},
   "source": [
    "# Random Forest Regression (London)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b5057d-2e57-41cf-8c66-704529109e5d",
   "metadata": {},
   "source": [
    "### Random Forest - lower price dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43458b71-dd68-4914-934b-26a3eb922f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X = ldn_filtered_low.drop('price', axis=1).values\n",
    "y = ldn_filtered_low['price'].values\n",
    "y = np.log10(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a052d1-1309-455f-a137-be8de541bfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce123f4-77db-4374-b67a-713ae1b9231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(max_depth=8, n_estimators = 100, random_state = 0)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b7bf7e-5546-4a3b-8efe-759725e98934",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual': np.round(10 ** y_test, 0), \n",
    "                   'Predicted': np.round(10 ** y_pred, 0)})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4602954-fd49-465b-95aa-920160392374",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Price mean:', np.round(np.mean(y), 2))  \n",
    "print('Price std:', np.round(np.std(y), 2))\n",
    "print('RMSE:', np.round(np.sqrt(metrics.mean_squared_error(y_test, rfr.predict(X_test))), 2))\n",
    "print('R2 score train:', np.round(r2_score(y_train, rfr.predict(X_train), multioutput='variance_weighted'), 2))\n",
    "print('R2 score test:', np.round(r2_score(y_test, rfr.predict(X_test), multioutput='variance_weighted'), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3342d7aa-c948-427d-8434-51f1bd8c4042",
   "metadata": {},
   "source": [
    "### Random Forest - higher price dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3e36c5-b25e-470e-9e9a-38c683374789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X = ldn_filtered_high.drop('price', axis=1)\n",
    "y = ldn_filtered_high['price']\n",
    "y = np.log10(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fcd499-3175-4e6e-a916-d73c3c71c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93df124-24fb-4d98-a702-56febbf7cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(max_depth=8, n_estimators = 100, random_state = 0)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e73e1-1692-47dd-ae52-3532c33c6115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual': np.round(10 ** y_test, 0), \n",
    "                   'Predicted': np.round(10 ** y_pred, 0)})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684df02d-3838-4851-9ff3-56553be4054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Price mean:', np.round(np.mean(y), 2))  \n",
    "print('Price std:', np.round(np.std(y), 2))\n",
    "print('RMSE:', np.round(np.sqrt(metrics.mean_squared_error(y_test, rfr.predict(X_test))), 2))\n",
    "print('R2 score train:', np.round(r2_score(y_train, rfr.predict(X_train), multioutput='variance_weighted'), 2))\n",
    "print('R2 score test:', np.round(r2_score(y_test, rfr.predict(X_test), multioutput='variance_weighted'), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283fadbc-24bf-43bf-86c7-63b7db6370ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 20)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 150, num = 11)]\n",
    "min_samples_split = [2, 5, 10, 20]\n",
    "min_samples_leaf = [1, 2, 4, 10, 20]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "parametrs = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50130309-f1fc-4e9e-a61c-4bddc62f982c",
   "metadata": {},
   "source": [
    "# Statsmodels OLS (Amsterdam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b897c935-3eac-425b-8cca-7fa6ffcab7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set response column and df to use\n",
    "response_col = 'price'\n",
    "df_to_use_ols = ams\n",
    "\n",
    "# set X matrix and y \n",
    "X = df_to_use_ols.drop(response_col, axis=1)\n",
    "X = sm.add_constant(X)\n",
    "y = df_to_use_ols[response_col]\n",
    "\n",
    "# fit and predict\n",
    "est = sm.OLS(y.astype(float), X.astype(float)).fit()\n",
    "ypred = est.predict(X)\n",
    "\n",
    "# evaluate\n",
    "rmse = np.sqrt(mean_squared_error(y, ypred))\n",
    "print(rmse)\n",
    "\n",
    "# show stats summary\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2807aa-873d-498d-9b9f-19d210d841cf",
   "metadata": {},
   "source": [
    "# Statsmodels OLS (London)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd5ff0-391a-4d4d-ab88-bc2f89b56200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set response column and df to use\n",
    "response_col = 'price'\n",
    "df_to_use_ols = ldn\n",
    "\n",
    "# set X matrix and y \n",
    "X = df_to_use_ols.drop(response_col, axis=1)\n",
    "X = sm.add_constant(X)\n",
    "y = df_to_use_ols[response_col]\n",
    "\n",
    "# fit and predict\n",
    "est = sm.OLS(y.astype(float), X.astype(float)).fit()\n",
    "ypred = est.predict(X)\n",
    "\n",
    "# evaluate\n",
    "rmse = np.sqrt(mean_squared_error(y, ypred))\n",
    "print(rmse)\n",
    "\n",
    "# show stats summary\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5674fd-1a4d-43af-9de3-c110dc0871c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29bb86b6-aee4-4cd7-955a-61f5d2f77df9",
   "metadata": {},
   "source": [
    "# Using Random Forest Regressor for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6323973a-b8b8-4cd6-b9fc-5654e70429e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amsterdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f8a97f-7079-49bb-bc1d-7dc7a517987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_ams = pd.read_csv('/Users/georginadangerfield/Downloads/airbnb_amsterdam/listings_details.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0408980c-c871-4347-9b1e-2e251df61e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_ams['price'] = listings_ams['price'].str.replace(',', '')\n",
    "listings_ams['price'] = listings_ams['price'].str.replace('$', '')\n",
    "listings_ams['price'] = listings_ams['price'].astype(float)\n",
    "listings_ams = listings_ams.loc[(listings_ams.price <= 600) & (listings_ams.price > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe016b1-3026-4437-b4d5-8ae016d0c100",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_ams.amenities = listings_ams.amenities.str.replace(\"[{}]\", \"\").str.replace('\"', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233a93df-4929-4e01-99e4-d1c29f418c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_ams.amenities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad71b80-1b2b-4873-b612-26c753f4b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer =  CountVectorizer(tokenizer=lambda x: x.split(','))\n",
    "amenities = count_vectorizer.fit_transform(listings_ams['amenities'])\n",
    "df_amenities_ams = pd.DataFrame(amenities.toarray(), columns=count_vectorizer.get_feature_names())\n",
    "df_amenities_ams = df_amenities_ams.drop('',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577250ce-a836-4388-ac9b-4648f06a020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =  ['host_is_superhost', 'host_identity_verified', 'host_has_profile_pic',\n",
    "                   'is_location_exact', 'requires_license', 'instant_bookable',\n",
    "                   'require_guest_profile_picture', 'require_guest_phone_verification']\n",
    "for c in columns:\n",
    "    listings_ams[c] = listings_ams[c].replace('f',0,regex=True)\n",
    "    listings_ams[c] = listings_ams[c].replace('t',1,regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b5dfef-2f13-4fcc-8fc6-eac43aad15db",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_ams['security_deposit'] = listings_ams['security_deposit'].fillna(value=0)\n",
    "listings_ams['security_deposit'] = listings_ams['security_deposit'].replace( '[\\$,)]','', regex=True ).astype(float)\n",
    "listings_ams['cleaning_fee'] = listings_ams['cleaning_fee'].fillna(value=0)\n",
    "listings_ams['cleaning_fee'] = listings_ams['cleaning_fee'].replace( '[\\$,)]','', regex=True ).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ba86b-a3ac-4e81-8040-3a885bfc277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_new_ams = listings_ams[['host_is_superhost', 'host_identity_verified', 'host_has_profile_pic','is_location_exact', \n",
    "                         'requires_license', 'instant_bookable', 'require_guest_profile_picture', \n",
    "                         'require_guest_phone_verification', 'security_deposit', 'cleaning_fee', \n",
    "                         'host_listings_count', 'host_total_listings_count', 'minimum_nights',\n",
    "                     'bathrooms', 'bedrooms', 'guests_included', 'number_of_reviews','review_scores_rating', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dde8463-08be-4f22-867e-5adf1a21411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in listings_new_ams.columns[listings_new_ams.isnull().any()]:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccb4c66-b257-480c-a47e-4ee45d6ed943",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in listings_new_ams.columns[listings_new_ams.isnull().any()]:\n",
    "    listings_new_ams[col] = listings_new_ams[col].fillna(listings_new_ams[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8041b0-5d86-4412-8682-977f92a221ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_feature in ['zipcode', 'property_type', 'room_type', 'cancellation_policy', 'neighbourhood_cleansed', 'bed_type']:\n",
    "    listings_new_ams = pd.concat([listings_new_ams, pd.get_dummies(listings_ams[cat_feature])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764ea7ae-1bbc-4fe0-ac41-61fd28febec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_new_ams = pd.concat([listings_new_ams, df_amenities_ams], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185085dd-29b2-4fd1-ac75-2b2b9a82c1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = listings_new_ams['price']\n",
    "x = listings_new_ams.drop('price', axis =1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state=1)\n",
    "rf = RandomForestRegressor(n_estimators=500, \n",
    "                               criterion='mse', \n",
    "                               random_state=3, \n",
    "                               n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_train_pred = rf.predict(X_train)\n",
    "y_test_pred = rf.predict(X_test)\n",
    "rmse_rf= (mean_squared_error(y_test,y_test_pred))**(1/2)\n",
    "\n",
    "print('RMSE test: %.3f' % rmse_rf)\n",
    "print('R^2 test: %.3f' % (r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb6f8a6-98f5-4fbc-8265-538703d67802",
   "metadata": {},
   "source": [
    "### Feature Importance of Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad97458-d924-4207-b08e-d046791d8c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_df = pd.DataFrame()\n",
    "\n",
    "coefs_df['est_int'] = X_train.columns\n",
    "coefs_df['coefs'] = rf.feature_importances_\n",
    "coefs_df.sort_values('coefs', ascending=False).head(20)\n",
    "coefs_df = pd.DataFrame()\n",
    "\n",
    "coefs_df['est_int'] = X_train.columns\n",
    "coefs_df['coefs'] = rf.feature_importances_\n",
    "coefs_df.sort_values('coefs', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74e02b4-6a1c-4cf5-b8e6-d9fac120a208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a3da17-afd0-421a-a79b-f6bc0e2c7906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badd72eb-bf21-460e-a6ca-72a736cc5b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_ldn = pd.read_csv('/Users/georginadangerfield/Downloads/assignment/airbnb_london/listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225cb86-4d01-4a61-bce7-0665c80d52b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_ldn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ad9c9b-d847-4dfc-bf4c-f001c52cfd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_ldn['price'] = listings_ldn['price'].str.replace(',', '')\n",
    "listings_ldn['price'] = listings_ldn['price'].str.replace('$', '')\n",
    "listings_ldn['price'] = listings_ldn['price'].astype(float)\n",
    "listings_ldn = listings_ldn.loc[(listings_ldn.price <= 600) & (listings_ldn.price > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e2f14-9950-44b4-9bfb-f0b23a108e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_ldn.amenities = listings_ldn.amenities.str.replace(\"[{}]\", \"\").str.replace('\"', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0886d26a-08f3-4c57-b836-3f2af9cda2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_ldn.amenities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca1fd62-c54f-4099-8352-3add9d745efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer =  CountVectorizer(tokenizer=lambda x: x.split(','))\n",
    "amenities = count_vectorizer.fit_transform(listings_ldn['amenities'])\n",
    "df_amenities_ldn = pd.DataFrame(amenities.toarray(), columns=count_vectorizer.get_feature_names())\n",
    "df_amenities_ldn = df_amenities_ldn.drop('',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252c822c-ab15-40f1-9701-42a3661db707",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =  ['host_is_superhost', 'host_identity_verified', 'host_has_profile_pic',\n",
    "                   'is_location_exact', 'requires_license', 'instant_bookable',\n",
    "                   'require_guest_profile_picture', 'require_guest_phone_verification']\n",
    "for c in columns:\n",
    "    listings_ldn[c] = listings_ldn[c].replace('f',0,regex=True)\n",
    "    listings_ldn[c] = listings_ldn[c].replace('t',1,regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f91e216-1442-4cb6-b3f5-494b4ec6b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_ldn['security_deposit'] = listings_ldn['security_deposit'].fillna(value=0)\n",
    "listings_ldn['security_deposit'] = listings_ldn['security_deposit'].replace( '[\\$,)]','', regex=True ).astype(float)\n",
    "listings_ldn['cleaning_fee'] = listings_ldn['cleaning_fee'].fillna(value=0)\n",
    "listings_ldn['cleaning_fee'] = listings_ldn['cleaning_fee'].replace( '[\\$,)]','', regex=True ).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c261c8f4-e835-4682-8b56-bab89e920bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_new_ldn = listings_ldn[['host_is_superhost', 'host_identity_verified', 'host_has_profile_pic','is_location_exact', \n",
    "                         'requires_license', 'instant_bookable', 'require_guest_profile_picture', \n",
    "                         'require_guest_phone_verification', 'security_deposit', 'cleaning_fee', \n",
    "                         'host_listings_count', 'host_total_listings_count', 'minimum_nights',\n",
    "                     'bathrooms', 'bedrooms', 'guests_included', 'number_of_reviews','review_scores_rating', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f195b380-af0c-41cd-9add-e8032c2cc03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in listings_new_ldn.columns[listings_new_ldn.isnull().any()]:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de01414-6b5b-4e7a-b4bb-df0ead3bff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in listings_new_ldn.columns[listings_new_ldn.isnull().any()]:\n",
    "    listings_new_ldn[col] = listings_new_ldn[col].fillna(listings_new_ldn[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834e645f-54e4-42db-bc06-db93d6aafcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_feature in ['zipcode', 'property_type', 'room_type', 'cancellation_policy', 'neighbourhood_cleansed', 'bed_type']:\n",
    "    listings_new_ldn = pd.concat([listings_new_ldn, pd.get_dummies(listings_ldn[cat_feature])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c11c8-b054-423e-a65c-68e7cd99d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_new_ldn = pd.concat([listings_new_ldn, df_amenities_ldn], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50276620-4bd7-498e-ab39-ec8508b0f959",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(listings_new_ldn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8bf5c5-2815-4232-bc66-46f8c494d2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking a random sample of listings_new_ldn, as for some reason the model had still not run after nearly \n",
    "# 2 hours (the Amsterdam model only took a few mins)\n",
    "listings_new_ldn = listings_new_ldn.sample(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be3617-a52d-4a0b-8782-372d23c71fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(listings_new_ldn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe99184-1cfc-43c5-9f3f-bc7151e841ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = listings_new_ldn['price']\n",
    "x = listings_new_ldn.drop('price', axis =1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f305e863-1e36-4c6e-9f7c-6d79c194a9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a74ed22-fe09-44b0-9526-c2608c3f8375",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = rf.predict(X_train)\n",
    "y_test_pred = rf.predict(X_test)\n",
    "rmse_rf= (mean_squared_error(y_test,y_test_pred))**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002eb78f-edc2-4525-832b-745f4ecbe828",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSE test: %.3f' % rmse_rf)\n",
    "print('R^2 test: %.3f' % (r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5600174f-bac0-4f1a-b253-b71ac330468f",
   "metadata": {},
   "source": [
    "### Feature Importance of Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c3e1fe-462b-440a-b3d2-d951cadf7ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_df = pd.DataFrame()\n",
    "\n",
    "coefs_df['est_int'] = X_train.columns\n",
    "coefs_df['coefs'] = rf.feature_importances_\n",
    "coefs_df.sort_values('coefs', ascending=False).head(20)\n",
    "coefs_df = pd.DataFrame()\n",
    "\n",
    "coefs_df['est_int'] = X_train.columns\n",
    "coefs_df['coefs'] = rf.feature_importances_\n",
    "coefs_df.sort_values('coefs', ascending=False).head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
